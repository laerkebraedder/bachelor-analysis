---
title: "salience"
author: "Lærke Brædder"
date: "11/2/2021"
output: html_document
---
## Analysis of sub-experiment 1, salience. We want to analyze the time it takes for the image to emerge (rt) as a function of the three compositional dimensions: Blank space (b), noise (n), and complexity (c).

## Loading data and libraries
```{r Loading data and packages}
pacman::p_load(tidyverse,
               lmerTest,
               brms,
               fitdistrplus, # xxx Double check if you actually need these last three. What do they do?
               ggbeeswarm,
               svglite)

# Loading the logfiles and binding them into one big data frame:
filePaths1 <- list.files("data/logfiles-salience-big/", "\\.csv$", full.names = TRUE)
dfs <- do.call(rbind, lapply(filePaths1, read.csv))

# Cleaning the data up a little:
dfs <- dfs %>% rename(RT = Reaction_time) #Renaming the reaction time variable to RT
dfs <- subset(dfs, RT > 0.2) # Removing impossibly fast rt's.
dfs$Correct <- as.factor(dfs$Correctness) #Creating a new column for correctness where it is a factor. The factor column is named 'Correct'
dfs <- subset(dfs,!is.na(Correct)) #Removing incorrect responses from the df. xxx what is actually happening here?
dfs$ID <- as.factor(dfs$ID)
#d <- subset(d,ID!=66) # Excluding participant with all extremely low RTs. Lærke: here they exclude participant 66 due to extremely low rt's, I will have to look through my data to see in this is necessary. I will, however, have to exclude participant 014 and 017 due to them having their boxes completely merged on the screen:
dfs <- subset(dfs, ID != 014)
dfs <- subset(dfs, ID != 017)

dfs$Complexity <- ordered(dfs$Complexity) 
dfs$Noise <- ordered(dfs$Noise)
dfs$BlankSpace <- ordered(dfs$BlankSpace)

# xxx I am not sure what this, from the original script, does:
## d$PeriodL <- d$PeriodL - 2
## dC <- subset(d,Correct==1)
## dC$RT1 <- dC$RT/max(dC$RT)


```


## Exploratory visualization (xxx obs: this is pretty much an exact replica of the 2020 script) I am gonna run with gamma as well
```{r Exploratory Visualization}
# Okay, the reason why I don't need a Type column in because I only have the idealized stim in this dataset. I do not have any trials with original engravings as stim.

# Double-checking the RTs
ggplot(dfs, aes(RT)) + 
  geom_density(aes(fill = Correct, group = Correct, color = Correct), alpha = 0.3) +
  NULL
# original: It looks like a nice gamma, but there is a 0 second mode in correct = 0 (Lærke: I don't think there is in mine, but I will have to check what it looks like in theirs). xxx Lærke: Why is there a correct=0? didn't I remove those?


## By participant
ggplot(dfs, aes(RT)) + 
  geom_density(aes(fill = ID, group = ID, color = ID), alpha = 0.3) +
  guides(fill = FALSE, group = FALSE, color = FALSE) +
  NULL

### Distribution analysis by participant
C1 = subset(dfs, Correctness == 1)
for (i in unique(dfs$ID)){
  x = C1$RT[C1$ID == i]
  fn <- fitdist(x, "norm")
  Normal = summary(fn)$aic
  fln <- fitdist(x, "lnorm")
  LogNormal = summary(fln)$aic
  fg <- fitdist(x, "gamma")
  Gamma=summary(fg)$aic
  x<- data.frame(ID = i, Normal, LogNormal, Gamma)
  if (exists("FitData")){FitData = rbind(FitData, x)}else{FitData=x}
}

C1 <- FitData %>% gather(Distribution, Fit, Normal:Gamma, na.rm = FALSE, convert = FALSE)

ggplot(C1, aes(Distribution, Fit)) +
  geom_violin() +
  geom_beeswarm(aes(color = Distribution))

# Original: Definitely not normal, not super persuasive difference between lognormal and gamma
# Original: Conceptual reflection says gamma
# xxx Lærke: Look at their data to compare

## Let's explore accuracy and rt by the compositional dimensions
# Complexity:
ggplot(dfs, aes(Correct)) +
  geom_bar(stat = "count") + facet_wrap(.~ Complexity)

ggplot(subset(dfs, Correct == 1), aes(Complexity, RT)) +
  geom_violin() +
  geom_beeswarm(aes(color = Complexity))

# Noise:
ggplot(dfs, aes(Correct)) +
  geom_bar(stat="count") + facet_wrap(.~ Noise)

ggplot(subset(dfs,Correct==1),aes(Noise, RT)) +
  geom_violin() +
  geom_beeswarm(aes(color = Noise))

# Blank space:
ggplot(dfs, aes(Correct)) +
  geom_bar(stat="count") + facet_wrap(.~ BlankSpace)

ggplot(subset(dfs,Correct==1),aes(BlankSpace, RT)) +
  geom_violin() +
  geom_beeswarm(aes(color=BlankSpace))

# xxx these are the same whether or not I filter out incorrect answers. But why are we looking at then if I filtered them out? didn't I?

```


## (xxx in the 2020 study they also have this:) "Is accuracy affected by period? Signal Detection Theory model of accuracy" - Accuracy (Correct) as a function of composition. Testing to see how the compositional dimensions affect response accuracy.


### Is RT affected by the compositional dimensions?
models: 
 - "s" stands for salience (in case later on I have both salience, memory, and aesthetics models in my environment)
 - "f" stands for formula
 - "m" stands for model
 - "c" stands for complecity
 - "n" stands for noise
 - "b" stands for blank space
 
 - s_c_f1
 - 

```{r complexity}

CHAINS = 2
ITER = 4000   # many is good (more reliable), but takes longer time. Originally they had 8e3. Be aware of warnings.
CONTROLS = list(
  max_treedepth = 20,
  adapt_delta=0.999
  )


# Models conditioning rate only
s_c_f1 <- bf(RT ~ 1 + Complexity + (1 + Complexity | ID) + (1|Stimulus)) #!!! Don't need random effects for orientation in order to keep it simple. !!! this is an assumption, that we can make observations across orientations. Maybe have it as a fixed effect interaction even? How does orientation modulate complexity? if this is non significant then all is good.


# !!! because the complexity is ordered, I only need to run one model because i get one estimate for linear prediction and one for quadratic


#########################
# !!! evid.ratio is what i have to use as an expression of whether the effect is credible or not. x times more evidence for the hypothesis we are testing than all other hypotheses. Rule of thumb ratio over 3 is credible, < 3 is anectodal. post.prob 

# make one model for each compositional dimension. ordinals. then go look at the hypotheses. hypothesis(modelName, "complexityL > 0", class = "b") and hypothesis(modelName, "complexityQ > 0", class = "b"). if evid.ratio is inf then it is very good. (otherwise try class = "bsp", maybe for interactions)
#########################

# xxx Q: should i make subsets where I remove trials where dimensions of the same level are being compared? like I do in the aesthetics exp?
# xxx Q: How do I know whether to use the linear or the quadratic beta in my hypothesis testing?


# Get the priors to be set
get_prior(s_c_f1, dfs, family = Gamma(link="log"))


s_c_prior <- c(
           prior(normal(0, .3), class = Intercept),
           prior(normal(0, .1), class = b),
           prior(normal(0, .3), class = sd),   #not too much constraint, pretty high
           prior(lkj(5),      class=cor))

s_c_m1_prior <- brm(s_c_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_c_prior,
                   sample_prior = "only",
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS)
pp_check(s_c_m1_prior, nsamples = 100) # cant see anything but that may not be so bad. make prior post check


s_c_m1 <- brm(s_c_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_c_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_c_m1")
s_c_m1 <- add_ic(s_c_m1,ic = "loo",cores=CHAINS)


#save(s_c_m1, s_c_m2, file = "Models/Salience_RT_Models_complexity")

# Summarizing and visualizing results
print(summary(s_c_m1))
print(marginal_effects(s_c_m1))
#print(hypothesis(s_c_m1, "Complexity < 0")) #xxx Not sure it this is correct or is I need something like Complexity.L < Complexity.Q #Not sure how to handle this

print(hypothesis(s_c_m1, "Complexity.L < 0", class = "b"))
print(hypothesis(s_c_m1, "Complexity.Q < 0", class = "b"))

plot(hypothesis(s_c_m1, "Complexity.L < 0", class = "b"))
```


```{r Noise}
# Models conditioning rate only
s_n_f1 <- bf(RT ~ 1 + Noise + (1 + Noise | ID) + (1|Stimulus)) 


# Get the priors to be set
get_prior(s_n_f1, dfs, family = Gamma(link="log"))


s_n_prior <- c(
           prior(normal(0, .3), class = Intercept),
           prior(normal(0, .1), class = b),
           prior(normal(0, .3), class = sd),   #not too much constraint, pretty high
           prior(lkj(5),      class=cor))

s_n_m1_prior <- brm(s_n_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_n_prior,
                   sample_prior = "only",
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS)

pp_check(s_n_m1_prior, nsamples = 100) # cant see anything but that may not be so bad. make prior post check


s_n_m1 <- brm(s_n_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_n_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_n_m1")
s_n_m1 <- add_ic(s_n_m1,ic = "loo",cores=CHAINS)


#save(s_c_m1, s_c_m2, file = "Models/Salience_RT_Models_complexity")

# Summarizing and visualizing results
print(summary(s_n_m1))
print(marginal_effects(s_n_m1))
print(conditional_effects(s_n_m1))
print(hypothesis(s_n_m1, "Noise.Q < 0")) 
print(hypothesis(s_n_m1, "Noise.L < 0")) 
plot(hypothesis(s_n_m1, "Noise.L < 0"))
```


```{r Blank Space}
# Models conditioning rate only
s_b_f1 <- bf(RT ~ 1 + BlankSpace + (1 + BlankSpace | ID) + (1|Stimulus)) 


# Get the priors to be set
get_prior(s_b_f1, dfs, family = Gamma(link="log"))


s_b_prior <- c(
           prior(normal(0, .3), class = Intercept),
           prior(normal(0, .1), class = b),
           prior(normal(0, .3), class = sd),   #not too much constraint, pretty high
           prior(lkj(5),      class=cor))

s_b_m1_prior <- brm(s_b_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_n_prior,
                   sample_prior = "only",
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS)

pp_check(s_b_m1_prior, nsamples = 100) # cant see anything but that may not be so bad. make prior post check


s_b_m1 <- brm(s_b_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_b_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_b_m1")
s_b_m1 <- add_ic(s_b_m1,ic = "loo",cores=CHAINS)


#save(s_b_m1 file = "models/salience/s_b_m1")

# Summarizing and visualizing results
print(summary(s_b_m1))
print(marginal_effects(s_b_m1))
print(hypothesis(s_b_m1, "BlankSpace.Q < 0")) 
print(hypothesis(s_b_m1, "BlankSpace.L < 0")) 
plot(hypothesis(s_b_m1, "BlankSpace.L < 0"))
```



### Plots of the RT findings

```{r outlier removal xxx not working}
removeOuts <- function(ts, threshold){
  higher_threshold_condition <- ts > (mean(ts, na.rm = T) + (threshold*sd(ts, na.rm = T)))
  lower_threshold_condition <- ts < (mean(ts, na.rm = T) - (threshold*sd(ts, na.rm = T)))
  ts[higher_threshold_condition] <- NA
  ts[lower_threshold_condition] <- NA
  return(ts)
}

dfs_noOuts <- dfs

threshold = 3
dfs_noOuts$RT <- removeOuts(dfs_noOuts$RT, threshold)

dfs_noOuts <- na.omit(dfs_noOuts)
```


```{r without outliers}
## Plot for the main manuscript - Figure N
dfs_noOuts_agg <- dfs_noOuts %>% group_by(ID, Complexity, Noise, BlankSpace) %>% dplyr::summarize(
  mRT = mean(RT, na.rm=T),
  sdRT = sd(RT, na.rm=T),
  mRT_log = mean(log(RT), na.rm=T),
  sdRT_log = sd(log(RT), na.rm=T))

dfs_noOuts_agg$Complexity <- as.numeric(dfs_noOuts_agg$Complexity)
dfs_noOuts_agg$Noise <- as.numeric(dfs_noOuts_agg$Noise)
dfs_noOuts_agg$BlankSpace <- as.numeric(dfs_noOuts_agg$BlankSpace)

# Complexity plot:
s_CPlot1 <- ggplot(subset(dfs_noOuts_agg, mRT_log > 0), aes(Complexity, mRT)) + 
  geom_line(aes(group=ID,color=ID),alpha=0.3) +
  geom_point(aes(group=ID,color=ID),alpha=0.3)+
  geom_smooth(method=lm) +
  theme_classic() +
  ylab("Time to emerge (seconds)") +
  xlab("Complexity") +
  scale_color_discrete(guide=FALSE) +
  scale_x_continuous(breaks = c(1,2,3),labels=c("Low", "Medium", "High")) +
  NULL

# Noise plot:
s_NPlot1 <- ggplot(subset(dfs_noOuts_agg, mRT_log > 0), aes(Noise, mRT)) + 
  geom_line(aes(group=ID,color=ID),alpha=0.3) +
  geom_point(aes(group=ID,color=ID),alpha=0.3)+
  geom_smooth(method=lm) +
  theme_classic() +
  ylab("Time to emerge (seconds)") +
  xlab("Noise") +
  scale_color_discrete(guide=FALSE) +
  scale_x_continuous(breaks = c(1,2,3),labels=c("Low", "Medium", "High")) +
  NULL

# Blank space plot:
s_BPlot1 <- ggplot(subset(dfs_noOuts_agg, mRT_log > 0), aes(BlankSpace, mRT)) + 
  geom_line(aes(group=ID,color=ID),alpha=0.3) +
  geom_point(aes(group=ID,color=ID),alpha=0.3)+
  geom_smooth(method=lm) +
  theme_classic() +
  ylab("Time to emerge (seconds)") +
  xlab("Blank Space") +
  scale_color_discrete(guide=FALSE) +
  scale_x_continuous(breaks = c(1,2,3),labels=c("Low", "Medium", "High")) +
  NULL

library(patchwork)
s_CPlot1 +
  s_NPlot1 +
  s_BPlot1

#ggsave("Plots/s_CPlot.svg", plot = s_CPlot)


```


```{r with outliers}
## Plot for the main manuscript - Figure N
dfs_agg <- dfs %>% group_by(ID, Complexity, Noise, BlankSpace) %>% dplyr::summarize(
  mRT = mean(RT, na.rm=T),
  sdRT = sd(RT, na.rm=T),
  mRT_log = mean(log(RT), na.rm=T),
  sdRT_log = sd(log(RT), na.rm=T))

dfs_agg$Complexity <- as.numeric(dfs_agg$Complexity)
dfs_agg$Noise <- as.numeric(dfs_agg$Noise)
dfs_agg$BlankSpace <- as.numeric(dfs_agg$BlankSpace)

# Complexity plot:
s_CPlot <- ggplot(subset(dfs_agg, mRT_log > 0), aes(Complexity, mRT)) + 
  geom_line(aes(group=ID,color=ID),alpha=0.3) +
  geom_point(aes(group=ID,color=ID),alpha=0.3)+
  geom_smooth(method=lm) +
  theme_classic() +
  ylab("Time to emerge (seconds)") +
  xlab("Complexity") +
  scale_color_discrete(guide=FALSE) +
  scale_x_continuous(breaks = c(1,2,3),labels=c("Low", "Medium", "High")) +
  NULL

# Noise plot:
s_NPlot <- ggplot(subset(dfs_agg, mRT_log > 0), aes(Noise, mRT)) + 
  geom_line(aes(group=ID,color=ID),alpha=0.3) +
  geom_point(aes(group=ID,color=ID),alpha=0.3)+
  geom_smooth(method=lm) +
  theme_classic() +
  ylab("Time to emerge (seconds)") +
  xlab("Noise") +
  scale_color_discrete(guide=FALSE) +
  scale_x_continuous(breaks = c(1,2,3),labels=c("Low", "Medium", "High")) +
  NULL

# Blank space plot:
s_BPlot <- ggplot(subset(dfs_agg, mRT_log > 0), aes(BlankSpace, mRT)) + 
  geom_line(aes(group=ID,color=ID),alpha=0.3) +
  geom_point(aes(group=ID,color=ID),alpha=0.3)+
  geom_smooth(method=lm) +
  theme_classic() +
  ylab("Time to emerge (seconds)") +
  xlab("Blank Space") +
  scale_color_discrete(guide=FALSE) +
  scale_x_continuous(breaks = c(1,2,3),labels=c("Low", "Medium", "High")) +
  NULL

s_CPlot
s_CPlot1
s_NPlot
s_NPlot1
s_BPlot
s_BPlot1

library(patchwork)
s_CPlot +
  s_NPlot +
  s_BPlot

#ggsave("Plots/s_CPlot.svg", plot = s_CPlot)

```


Or plot the model - plot the posterior data:

```{r}
conditional_effects(modelName)

conditional_effects(modelName, effects = "parameter1:parameter2")[[1]]


plot(hypothesis(modelName, "Complexity < 0"))
```


