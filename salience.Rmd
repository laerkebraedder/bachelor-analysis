---
title: "salience"
author: "Lærke Brædder"
date: "11/2/2021"
output: html_document
---
## Analysis of sub-experiment 1, salience. We want to analyze the time it takes for the image to emerge (rt) as a function of the three compositional dimensions: Blank space (b), noise (n), and complexity (c).

## Loading data and libraries
```{r Loading data and packages}
pacman::p_load(tidyverse,
               lmerTest,
               brms,
               fitdistrplus, # xxx Double check if you actually need these last three. What do they do?
               ggbeeswarm,
               svglite)

# Loading the logfiles and binding them into one big data frame:
filePaths1 <- list.files("data/logfiles-salience-big/", "\\.csv$", full.names = TRUE)
dfs <- do.call(rbind, lapply(filePaths1, read.csv))

# Cleaning the data up a little:
dfs <- dfs %>% rename(RT = Reaction_time) #Renaming the reaction time variable to RT
dfs <- subset(dfs, RT > 0.2) # Removing impossibly fast rt's.
dfs$Correct <- as.factor(dfs$Correctness) #Creating a new column for correctness where it is a factor. The factor column is named 'Correct'
dfs <- subset(dfs,!is.na(Correct)) #Removing incorrect responses from the df. xxx what is actually happening here?
dfs$ID <- as.factor(dfs$ID)
#d <- subset(d,ID!=66) # Excluding participant with all extremely low RTs. Lærke: here they exclude participant 66 due to extremely low rt's, I will have to look through my data to see in this is necessary. I will, however, have to exclude participant 014 and 017 due to them having their boxes completely merged on the screen:
dfs <- subset(dfs, ID != 014)
dfs <- subset(dfs, ID != 017)

dfs$Complexity <- ordered(dfs$Complexity) 
dfs$Noise <- ordered(dfs$Noise)
dfs$BlankSpace <- ordered(dfs$BlankSpace)

#dfs$RT_std <- standardize(dfs$RT) #xxx should I even standardize? <- can´t use standardize for a gamma model, because it goes below zero. Is the method below ok?
# Option 1: Transform MSE so that it is on a 0-1 scale
dfs$RT_std = dfs$RT - min(dfs$RT)
dfs$RT_std = dfs$RT / max(dfs$RT)

# xxx I am not sure what this, from the original script, does:
## d$PeriodL <- d$PeriodL - 2
## dC <- subset(d,Correct==1)
## dC$RT1 <- dC$RT/max(dC$RT)


```


```{r outlier removal}
# Maybe not necessary? xxx probs don't do it
removeOuts <- function(ts, threshold){
  higher_threshold_condition <- ts > (mean(ts, na.rm = T) + (threshold*sd(ts, na.rm = T)))
  lower_threshold_condition <- ts < (mean(ts, na.rm = T) - (threshold*sd(ts, na.rm = T)))
  ts[higher_threshold_condition] <- NA
  ts[lower_threshold_condition] <- NA
  return(ts)
}

threshold = 3
dfs$RT <- removeOuts(dfs$RT, threshold)

dfs <- na.omit(dfs)

# The df went from 3430 observations to 3150 observations when removing outliers.
```


## Exploratory visualization (xxx obs: this is pretty much an exact replica of the 2020 script) I am gonna run with gamma as well
```{r Exploratory Visualization}
# Okay, the reason why I don't need a Type column in because I only have the idealized stim in this dataset. I do not have any trials with original engravings as stim.

# Double-checking the RTs
ggplot(dfs, aes(RT)) + 
  geom_density(aes(fill = Correct, group = Correct, color = Correct), alpha = 0.3) +
  NULL
# original: It looks like a nice gamma, but there is a 0 second mode in correct = 0 (Lærke: I don't think there is in mine, but I will have to check what it looks like in theirs). xxx Lærke: Why is there a correct=0? didn't I remove those?


## By participant
ggplot(dfs, aes(RT)) + 
  geom_density(aes(fill = ID, group = ID, color = ID), alpha = 0.3) +
  guides(fill = FALSE, group = FALSE, color = FALSE) +
  NULL

### Distribution analysis by participant
C1 = subset(dfs, Correctness == 1)
for (i in unique(dfs$ID)){
  x = C1$RT[C1$ID == i]
  fn <- fitdist(x, "norm")
  Normal = summary(fn)$aic
  fln <- fitdist(x, "lnorm")
  LogNormal = summary(fln)$aic
  fg <- fitdist(x, "gamma")
  Gamma=summary(fg)$aic
  x<- data.frame(ID = i, Normal, LogNormal, Gamma)
  if (exists("FitData")){FitData = rbind(FitData, x)}else{FitData=x}
}

C1 <- FitData %>% gather(Distribution, Fit, Normal:Gamma, na.rm = FALSE, convert = FALSE)

ggplot(C1, aes(Distribution, Fit)) +
  geom_violin() +
  geom_beeswarm(aes(color = Distribution))

# Original: Definitely not normal, not super persuasive difference between lognormal and gamma
# Original: Conceptual reflection says gamma
# xxx Lærke: Look at their data to compare

## Let's explore accuracy and rt by the compositional dimensions
# Complexity:
ggplot(dfs, aes(Correct)) +
  geom_bar(stat = "count") + facet_wrap(.~ Complexity)

ggplot(subset(dfs, Correct == 1), aes(Complexity, RT)) +
  geom_violin() +
  geom_beeswarm(aes(color = Complexity))

# Noise:
ggplot(dfs, aes(Correct)) +
  geom_bar(stat="count") + facet_wrap(.~ Noise)

ggplot(subset(dfs,Correct==1),aes(Noise, RT)) +
  geom_violin() +
  geom_beeswarm(aes(color = Noise))

# Blank space:
ggplot(dfs, aes(Correct)) +
  geom_bar(stat="count") + facet_wrap(.~ BlankSpace)

ggplot(subset(dfs,Correct==1),aes(BlankSpace, RT)) +
  geom_violin() +
  geom_beeswarm(aes(color=BlankSpace))

# xxx these are the same whether or not I filter out incorrect answers. But why are we looking at then if I filtered them out? didn't I?

```


## (xxx in the 2020 study they also have this:) "Is accuracy affected by period? Signal Detection Theory model of accuracy" - Accuracy (Correct) as a function of composition. Testing to see how the compositional dimensions affect response accuracy.


### Is RT affected by the compositional dimensions?
models: 
 - "s" stands for salience (in case later on I have both salience, memory, and aesthetics models in my environment)
 - "f" stands for formula
 - "m" stands for model
 - "c" stands for complecity
 - "n" stands for noise
 - "b" stands for blank space
 
 - s_c_f1
 - 

## COMPLEXITY MODELS xxx Run these again after outlier removal (27.11.2021)

# Models with and without random effects for orientation. These have standardized outcome variable (between 0 and 1). They have ordinal predictor variables.
```{r complexity 1}

CHAINS = 2
ITER = 4000   # many is good (more reliable), but takes longer time. Originally they had 8e3. Be aware of warnings.
CONTROLS = list(
  max_treedepth = 20,
  adapt_delta=0.999
  )


s_c_f1 <- bf(RT_std ~ 1 + Complexity + (1 + Complexity | ID) + (1 | Stimulus)) #!!! Don't need random effects for orientation in order to keep it simple. !!! this is an assumption, that we can make observations across orientations. Maybe have it as a fixed effect interaction even? How does orientation modulate complexity? if this is non significant then all is good. xxx Update: Kristian wrote that orientation does seem to have an effect, so we might wanna add it.
s_c_f2 <- bf(RT_std ~ 1 + Complexity + (1 + Complexity | ID) + (1 | Stimulus) + (1 | Orientation))

# !!! because the complexity is ordered, I only need to run one model because i get one estimate for linear prediction and one for quadratic


#########################
# !!! evid.ratio is what i have to use as an expression of whether the effect is credible or not. x times more evidence for the hypothesis we are testing than all other hypotheses. Rule of thumb ratio over 3 is credible, < 3 is anectodal. post.prob 

# make one model for each compositional dimension. ordinals. then go look at the hypotheses. hypothesis(modelName, "complexityL > 0", class = "b") and hypothesis(modelName, "complexityQ > 0", class = "b"). if evid.ratio is inf then it is very good. (otherwise try class = "bsp", maybe for interactions)
#########################

# xxx Q: should i make subsets where I remove trials where dimensions of the same level are being compared? like I do in the aesthetics exp?
# xxx Q: How do I know whether to use the linear or the quadratic beta in my hypothesis testing?


# Get the priors to be set
get_prior(s_c_f1, dfs, family = Gamma(link="log"))

s_c_prior <- c(
           prior(normal(0, .3), class = Intercept),
           prior(normal(0, .1), class = b),
           prior(normal(0, .3), class = sd),   #not too much constraint, pretty high
           prior(lkj(5),      class=cor))

s_c_m1_prior <- brm(s_c_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_c_prior,
                   sample_prior = "only",
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS)
pp_check(s_c_m1_prior, nsamples = 100) # cant see anything but that may not be so bad. make prior post check


s_c_m1 <- brm(s_c_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_c_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_c_m1")
s_c_m1 <- add_criterion(s_c_m1, criterion = c("bayes_R2", "loo"))
#s_c_m1 <- add_criterion(s_c_m1, criterion = c("bayes_R2", "loo"), moment_match = TRUE)


s_c_m2 <- brm(s_c_f2,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_c_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_c_m2")
s_c_m2 <- add_criterion(s_c_m2, criterion = c("bayes_R2", "loo"))
#s_c_m2 <- add_criterion(s_c_m2, criterion = c("bayes_R2", "loo"), moment_match = TRUE) 

#save(s_c_m1, s_c_m2, file = "Models/Salience_RT_Models_complexity")

# Summarizing and visualizing results
print(summary(s_c_m1))
print(marginal_effects(s_c_m1))
#print(hypothesis(s_c_m1, "Complexity < 0")) #xxx Not sure it this is correct or is I need something like Complexity.L < Complexity.Q #Not sure how to handle this
print(hypothesis(s_c_m1, "Complexity.L < 0", class = "b"))
print(hypothesis(s_c_m1, "Complexity.Q < 0", class = "b"))
plot(hypothesis(s_c_m1, "Complexity.L < 0", class = "b"))
plot(hypothesis(s_c_m1, "Complexity.Q < 0", class = "b"))


# m2
print(summary(s_c_m2))
print(marginal_effects(s_c_m2))
print(hypothesis(s_c_m2, "Complexity.L < 0", class = "b"))
print(hypothesis(s_c_m2, "Complexity.Q < 0", class = "b"))
plot(hypothesis(s_c_m2, "Complexity.L < 0", class = "b"))
```

# Models with and without random effects for orientation. These do not have standardized outcome variables. They have ordinal predictor variables. (i.e. they are the same as the models in the chunk above, except they have the original outcome variable scale)
```{r complexity 2}
s_c_f1.1 <- bf(RT ~ 1 + Complexity + (1 + Complexity | ID) + (1 | Stimulus)) #!!! Don't need random effects for orientation in order to keep it simple. !!! this is an assumption, that we can make observations across orientations. Maybe have it as a fixed effect interaction even? How does orientation modulate complexity? if this is non significant then all is good. xxx Update: Kristian wrote that orientation does seem to have an effect, so we might wanna add it.
s_c_f2.1 <- bf(RT ~ 1 + Complexity + (1 + Complexity | ID) + (1 | Stimulus) + (1 | Orientation))

# xxx Can I run with the same priors regardless of whether the outcome is scaled or not? I guess so.. The priors don't have anything to do with the outcome, I think? So we use the same priors as in the chunk above.

s_c_m1.1_prior <- brm(s_c_f1.1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_c_prior,
                   sample_prior = "only",
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS)
s_c_m2.1_prior <- brm(s_c_f2.1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_c_prior,
                   sample_prior = "only",
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS)

pp_check(s_c_m1.1_prior, nsamples = 100)
pp_check(s_c_m2.1_prior, nsamples = 100)


s_c_m1.1 <- brm(s_c_f1.1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_c_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_c_m1.1")
s_c_m1.1 <- add_criterion(s_c_m1.1, criterion = c("bayes_R2", "loo"))
#s_c_m1.1 <- add_criterion(s_c_m1.1, criterion = c("bayes_R2", "loo"), moment_match = TRUE)



s_c_m2.1 <- brm(s_c_f2.1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_c_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_c_m2.1")
s_c_m2.1 <- add_criterion(s_c_m2.1, criterion = c("bayes_R2", "loo")) 
#s_c_m2.1 <- add_criterion(s_c_m2.1, criterion = c("bayes_R2", "loo"), moment_match = TRUE) 


# Summarizing and visualizing results
# m1.1
print(summary(s_c_m1.1))
print(marginal_effects(s_c_m1.1))
print(hypothesis(s_c_m1.1, "Complexity.L < 0", class = "b"))
print(hypothesis(s_c_m1.1, "Complexity.Q < 0", class = "b"))
plot(hypothesis(s_c_m1.1, "Complexity.L < 0", class = "b"))
plot(hypothesis(s_c_m1.1, "Complexity.Q < 0", class = "b"))

# m2.1
print(summary(s_c_m2.1))
print(marginal_effects(s_c_m2.1))
print(hypothesis(s_c_m2.1, "Complexity.L < 0", class = "b"))
print(hypothesis(s_c_m2.1, "Complexity.Q < 0", class = "b"))
plot(hypothesis(s_c_m2.1, "Complexity.L < 0", class = "b"))
plot(hypothesis(s_c_m2.1, "Complexity.Q < 0", class = "b"))
```



## NOISE MODELS
# Models with and without random effects for orientation. These have standardized outcome variable (between 0 and 1). They have ordinal predictor variables.
```{r noise 1}
s_n_f1 <- bf(RT_std ~ 1 + Noise + (1 + Noise | ID) + (1 | Stimulus))
s_n_f2 <- bf(RT_std ~ 1 + Noise + (1 + Noise | ID) + (1 | Stimulus) + (1 | Orientation))


# Get the priors to be set
get_prior(s_n_f1, dfs, family = Gamma(link="log")) #xxx suggests having the lkj prior 1. Might wanna try that...

s_n_prior <- c(
           prior(normal(0, .3), class = Intercept), #xxx haven't checked the priors. These are the same as in the complexity models.
           prior(normal(0, .1), class = b),
           prior(normal(0, .3), class = sd),   #not too much constraint, pretty high
           prior(lkj(5),      class=cor))

s_n_m1_prior <- brm(s_n_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_c_prior,
                   sample_prior = "only",
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS)
pp_check(s_n_m1_prior, nsamples = 100) # cant see anything but that may not be so bad. make prior post check


s_n_m1 <- brm(s_n_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_n_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_n_m1")
#s_n_m1 <- add_criterion(s_n_m1, criterion = c("bayes_R2", "loo"), moment_match = TRUE)
s_n_m1 <- add_criterion(s_n_m1, criterion = c("bayes_R2", "loo"))


s_n_m2 <- brm(s_n_f2,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_n_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_n_m2")
#s_n_m2 <- add_criterion(s_n_m2, criterion = c("bayes_R2", "loo"), moment_match = TRUE) 
s_n_m2 <- add_criterion(s_n_m2, criterion = c("bayes_R2", "loo")) 

# Summarizing and visualizing results
print(summary(s_n_m1))
print(marginal_effects(s_n_m1))
print(hypothesis(s_n_m1, "Noise.L < 0", class = "b"))
print(hypothesis(s_n_m1, "Noise.Q < 0", class = "b"))
plot(hypothesis(s_n_m1, "Noise.L < 0", class = "b"))
plot(hypothesis(s_n_m1, "Noise.Q < 0", class = "b"))


# m2
print(summary(s_n_m2))
print(marginal_effects(s_n_m2))
print(hypothesis(s_n_m2, "Noise.L < 0", class = "b"))
print(hypothesis(s_n_m2, "Noise.Q < 0", class = "b"))
plot(hypothesis(s_n_m2, "Noise.L < 0", class = "b"))
plot(hypothesis(s_n_m2, "Noise.Q < 0", class = "b"))
```

# Models with and without random effects for orientation. These do not have standardized outcome variables. They have ordinal predictor variables. (i.e. they are the same as the models in the chunk above, except they have the original outcome variable scale)
```{r noise 2}
s_n_f1.1 <- bf(RT ~ 1 + Noise + (1 + Noise | ID) + (1 | Stimulus))
s_n_f2.1 <- bf(RT ~ 1 + Noise + (1 + Noise | ID) + (1 | Stimulus) + (1 | Orientation))


s_n_m1.1_prior <- brm(s_n_f1.1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_n_prior,
                   sample_prior = "only",
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS)
s_n_m2.1_prior <- brm(s_n_f2.1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_n_prior,
                   sample_prior = "only",
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS)

pp_check(s_n_m1.1_prior, nsamples = 100)
pp_check(s_n_m2.1_prior, nsamples = 100)


s_n_m1.1 <- brm(s_n_f1.1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_n_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_n_m1.1")
#s_n_m1.1 <- add_criterion(s_n_m1.1, criterion = c("bayes_R2", "loo"), moment_match = TRUE)
s_n_m1.1 <- add_criterion(s_n_m1.1, criterion = c("bayes_R2", "loo"))


s_n_m2.1 <- brm(s_n_f2.1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_n_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_n_m2.1")
s_n_m2.1 <- add_criterion(s_n_m2.1, criterion = c("bayes_R2", "loo")) 
#s_n_m2.1 <- add_criterion(s_n_m2.1, criterion = c("bayes_R2", "loo"), moment_match = TRUE) 

# Summarizing and visualizing results
# m1.1
print(summary(s_n_m1.1))
print(marginal_effects(s_n_m1.1))
print(hypothesis(s_n_m1.1, "Noise.L < 0", class = "b"))
print(hypothesis(s_n_m1.1, "Noise.Q < 0", class = "b"))
plot(hypothesis(s_n_m1.1, "Noise.L < 0", class = "b"))
plot(hypothesis(s_n_m1.1, "Noise.Q < 0", class = "b"))

# m2.1
print(summary(s_c_m2.1))
print(marginal_effects(s_c_m2.1))
print(hypothesis(s_n_m2.1, "Noise.L < 0", class = "b"))
print(hypothesis(s_n_m2.1, "Noise.Q < 0", class = "b"))
plot(hypothesis(s_n_m2.1, "Noise.L < 0", class = "b"))
plot(hypothesis(s_n_m2.1, "Noise.Q < 0", class = "b"))
```


```{r Blank Space (all)}

s_b_f1 <- bf(RT_std ~ 1 + BlankSpace + (1 + BlankSpace | ID) + (1 | Stimulus))
s_b_f2 <- bf(RT_std ~ 1 + BlankSpace + (1 + BlankSpace | ID) + (1 | Stimulus) + (1 | Orientation))


s_b_prior <- c(
           prior(normal(0, .3), class = Intercept), #xxx haven't checked the priors. These are the same as in the complexity models.
           prior(normal(0, .1), class = b),
           prior(normal(0, .3), class = sd),   #not too much constraint, pretty high
           prior(lkj(5),      class=cor))

s_b_m1 <- brm(s_b_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_b_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_b_m1")
s_b_m1 <- add_criterion(s_b_m1, criterion = c("bayes_R2", "loo")) 

s_b_m2 <- brm(s_b_f2,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_b_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_b_m2")
s_b_m2 <- add_criterion(s_b_m2, criterion = c("bayes_R2", "loo")) 


print(summary(s_b_m1))
print(marginal_effects(s_b_m1))
print(hypothesis(s_b_m1, "BlankSpace.L < 0", class = "b"))
print(hypothesis(s_b_m1, "BlankSpace.Q < 0", class = "b"))
plot(hypothesis(s_b_m1, "BlankSpace.L < 0", class = "b"))
plot(hypothesis(s_b_m1, "BlankSpace.Q < 0", class = "b"))

print(summary(s_b_m2))
print(marginal_effects(s_b_m2))
print(hypothesis(s_b_m2, "BlankSpace.L < 0", class = "b"))
print(hypothesis(s_b_m2, "BlankSpace.Q < 0", class = "b"))
plot(hypothesis(s_b_m2, "BlankSpace.L < 0", class = "b"))
plot(hypothesis(s_b_m2, "BlankSpace.Q < 0", class = "b"))

```


```{r Blank Space (all)}
s_b_f1.1 <- bf(RT ~ 1 + BlankSpace + (1 + BlankSpace | ID) + (1 | Stimulus))
s_b_f2.1 <- bf(RT ~ 1 + BlankSpace + (1 + BlankSpace | ID) + (1 | Stimulus) + (1 | Orientation))

s_b_m1.1 <- brm(s_b_f1.1,
                   family = Gamma(link="log"), #xxx the log link is because with reaction times we usually have a long tail on the distribution. since the dependent variable is rt, we model it as a gamma distribution link log. Choices motivated by previous studies' parameter choices.
                   data = dfs,
                   prior = s_b_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_b_m1.1")
#s_b_m1.1 <- add_criterion(s_b_m1.1, criterion = c("bayes_R2", "loo")) 
s_b_m1.1 <- add_criterion(s_b_m1.1, criterion = c("bayes_R2", "loo"), moment_match = TRUE)  #xxx what does moment match actually do? how come sometimes I need it and sometimes I don't (even on the same model, I think)?

s_b_m2.1 <- brm(s_b_f2.1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_b_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_b_m2.1")
s_b_m2.1 <- add_criterion(s_b_m2.1, criterion = c("bayes_R2", "loo")) 


print(summary(s_b_m1.1))
print(marginal_effects(s_b_m1.1))
print(hypothesis(s_b_m1.1, "BlankSpace.L < 0", class = "b"))
print(hypothesis(s_b_m1.1, "BlankSpace.Q < 0", class = "b"))
plot(hypothesis(s_b_m1.1, "BlankSpace.L < 0", class = "b"))
plot(hypothesis(s_b_m1.1, "BlankSpace.Q < 0", class = "b")) #interesting that we have a positive effect here, but on memorability we have the opposite effect of what we expected - memorywise it may be nice when things "gestalter sammen inde midt på skærmen" making it easier to remember
# discussion: salience: the stim were very small and complex

print(summary(s_b_m2.1))
print(marginal_effects(s_b_m2.1))
print(hypothesis(s_b_m2.1, "BlankSpace.L < 0", class = "b"))
print(hypothesis(s_b_m2.1, "BlankSpace.Q < 0", class = "b"))
plot(hypothesis(s_b_m2.1, "BlankSpace.L < 0", class = "b"))
plot(hypothesis(s_b_m2.1, "BlankSpace.Q < 0", class = "b"))
```





```{r Noise (old)}
# Models conditioning rate only
s_n_f1 <- bf(RT ~ 1 + Noise + (1 + Noise | ID) + (1|Stimulus)) 


# Get the priors to be set
get_prior(s_n_f1, dfs, family = Gamma(link="log"))


s_n_prior <- c(
           prior(normal(0, .3), class = Intercept),
           prior(normal(0, .1), class = b),
           prior(normal(0, .3), class = sd),   #not too much constraint, pretty high
           prior(lkj(5),      class=cor))

s_n_m1_prior <- brm(s_n_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_n_prior,
                   sample_prior = "only",
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS)

pp_check(s_n_m1_prior, nsamples = 100) # cant see anything but that may not be so bad. make prior post check


s_n_m1 <- brm(s_n_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_n_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_n_m1")
s_n_m1 <- add_ic(s_n_m1,ic = "loo",cores=CHAINS)


#save(s_c_m1, s_c_m2, file = "Models/Salience_RT_Models_complexity")

# Summarizing and visualizing results
print(summary(s_n_m1))
print(marginal_effects(s_n_m1))
print(conditional_effects(s_n_m1))
print(hypothesis(s_n_m1, "Noise.Q < 0")) 
print(hypothesis(s_n_m1, "Noise.L < 0")) 
plot(hypothesis(s_n_m1, "Noise.L < 0"))
```


```{r Blank Space (old)}
# Models conditioning rate only
s_b_f1 <- bf(RT ~ 1 + BlankSpace + (1 + BlankSpace | ID) + (1|Stimulus)) 


# Get the priors to be set
get_prior(s_b_f1, dfs, family = Gamma(link="log"))


s_b_prior <- c(
           prior(normal(0, .3), class = Intercept),
           prior(normal(0, .1), class = b),
           prior(normal(0, .3), class = sd),   #not too much constraint, pretty high
           prior(lkj(5),      class=cor))

s_b_m1_prior <- brm(s_b_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_n_prior,
                   sample_prior = "only",
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS)

pp_check(s_b_m1_prior, nsamples = 100) # cant see anything but that may not be so bad. make prior post check


s_b_m1 <- brm(s_b_f1,
                   family = Gamma(link="log"),
                   data = dfs,
                   prior = s_b_prior,
                   sample_prior = TRUE,
                   chains = CHAINS,cores=CHAINS,
                   iter = ITER,
                   control = CONTROLS,
                   file = "models/salience/s_b_m1")
s_b_m1 <- add_ic(s_b_m1,ic = "loo",cores=CHAINS)


#save(s_b_m1 file = "models/salience/s_b_m1")

# Summarizing and visualizing results
print(summary(s_b_m1))
print(marginal_effects(s_b_m1))
print(hypothesis(s_b_m1, "BlankSpace.Q < 0")) 
print(hypothesis(s_b_m1, "BlankSpace.L < 0")) 
plot(hypothesis(s_b_m1, "BlankSpace.L < 0"))
```



### Plots of the RT findings


```{r with outliers}
## Plot for the main manuscript - Figure N
dfs_agg <- dfs %>% group_by(ID, Complexity, Noise, BlankSpace) %>% dplyr::summarize(
  mRT = mean(RT, na.rm=T),
  sdRT = sd(RT, na.rm=T),
  mRT_log = mean(log(RT), na.rm=T),
  sdRT_log = sd(log(RT), na.rm=T))

dfs_agg$Complexity <- as.numeric(dfs_agg$Complexity)
dfs_agg$Noise <- as.numeric(dfs_agg$Noise)
dfs_agg$BlankSpace <- as.numeric(dfs_agg$BlankSpace)

# Complexity plot:
s_CPlot <- ggplot(subset(dfs_agg, mRT_log > 0), aes(Complexity, mRT)) + 
  geom_line(aes(group=ID,color=ID),alpha=0.3) +
  geom_point(aes(group=ID,color=ID),alpha=0.3)+
  geom_smooth(method=lm) +
  theme_classic() +
  ylab("Time to emerge (seconds)") +
  xlab("Complexity") +
  scale_color_discrete(guide=FALSE) +
  scale_x_continuous(breaks = c(1,2,3),labels=c("Low", "Medium", "High")) +
  NULL

# Noise plot:
s_NPlot <- ggplot(subset(dfs_agg, mRT_log > 0), aes(Noise, mRT)) + 
  geom_line(aes(group=ID,color=ID),alpha=0.3) +
  geom_point(aes(group=ID,color=ID),alpha=0.3)+
  geom_smooth(method=lm) +
  theme_classic() +
  ylab("Time to emerge (seconds)") +
  xlab("Noise") +
  scale_color_discrete(guide=FALSE) +
  scale_x_continuous(breaks = c(1,2,3),labels=c("Low", "Medium", "High")) +
  NULL

# Blank space plot:
s_BPlot <- ggplot(subset(dfs_agg, mRT_log > 0), aes(BlankSpace, mRT)) + 
  geom_line(aes(group=ID,color=ID),alpha=0.3) +
  geom_point(aes(group=ID,color=ID),alpha=0.3)+
  geom_smooth(method=lm) +
  theme_classic() +
  ylab("Time to emerge (seconds)") +
  xlab("Blank Space") +
  scale_color_discrete(guide=FALSE) +
  scale_x_continuous(breaks = c(1,2,3),labels=c("Low", "Medium", "High")) +
  NULL

s_CPlot
s_CPlot1
s_NPlot
s_NPlot1
s_BPlot
s_BPlot1

library(patchwork)
s_CPlot +
  s_NPlot +
  s_BPlot

#ggsave("Plots/s_CPlot.svg", plot = s_CPlot)

```


Or plot the model - plot the posterior data:

```{r}
conditional_effects(modelName)

conditional_effects(modelName, effects = "parameter1:parameter2")[[1]]


plot(hypothesis(modelName, "Complexity < 0"))
```


