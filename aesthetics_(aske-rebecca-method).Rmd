---
title: "aske_rebecca_experiment2"
author: "Aske & Rebecca"
date: "7 October 2020"
output: word_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



## Gather data
Load packages, data, wd etc. 

```{r}

# packages
pacman::p_load(brms, tidyverse,lmerTest,ggbeeswarm, lme4, rethinking, bayesplot)

citation("rethinking")
citation("bayesplot")

# WD
setwd("data")
```



Collect data from several csv files

```{r}
# import data from several csv files
filePaths2 <- list.files("data/logfiles-aesthetics/", "\\.csv$", full.names = TRUE)
dfa <- do.call(rbind, lapply(filePaths2, read.csv))


# Dummy coding two new response columns:
dfa <- dfa %>% 
  mutate(
    ResponseL = ifelse(Response == "left", 1, 0),
    ResponseR = ifelse(Response == "right", 1, 0)
    )


dfa <- dfa %>%    # xxx decide whether or not to have capital first letters
  mutate(
    ID = as.factor(ID),
    Age = as.factor(Age),
    Gender = as.factor(Gender),
    stimulusL = as.factor(stimulusL), #In original it says "left" (is this the correct alternative? xxx)
    stimulusR = as.factor(stimulusR), #In original it says "right" (is this the correct alternative? xxx)
    chainL = as.factor(chainL),       #xxx What does chain mean?
    chainR = as.factor(chainR),     
    responseL = as.factor(responseL), #xxx Do they have these dummy coded? update: I did it, is it correct?
    responseR = as.factor(responseR), 
    #generationL = as.factor(generationL),  #xxx what does that mean? is that the same as period? If yes, then I down below replace them with the compositional dimensions.
    #generationR= as.factor(generationR),
    
    ComplexityL = as.factor(ComplexityL),
    ComplexityR= as.factor(ComplexityR),
    NoiseL = as.factor(NoiseL),
    NoiseR= as.factor(NoiseR),
    BlankSpaceL = as.factor(BlankSpaceL),
    BlankSpaceR= as.factor(BlankSpaceR),
    
    Orei
    chainPair = as.factor(chainPair),
    reaction_time = reaction_time
  )


# Create csv in shared folder
write.csv(dfa,"data/exp2_dfa.csv", row.names = FALSE)
```




## Preprocess data
Load packages, wd, and data

```{r}
# packages
pacman::p_load(tidyverse,lmerTest,ggbeeswarm, lme4, rethinking, brms)

# import data from csv - Lærke: I guess this isn't actually necessary for me, but here goes:
dfa <- read_csv("data/exp2_dfa.csv")
```



Create stimPair column (look in one of the other scripts)

# xxx This is mostly in order except from the nrows (see xxx)
```{r}

# make empty dataframe
dfa_new <- dfa[0,] 


# create count
count = 1 


# the LOOP - add StimPairID column
for (group in 1:length(unique(dfa$chainPair))){
  
  ## for each chainpair loop through and create StimPair unique ID
  sub <- subset(dfa, chainPair == group)

  # Create list of target pictures in the chain group (all 24 pics are represented in at least one participant)
  stimuli1 <- unique(sub$left) %>% as.data.frame()
  stimuli2 <- unique(sub$right) %>% as.data.frame()
  stimuli3 <- rbind(stimuli1, stimuli2)

  colnames(stimuli3)[1] <- "stim"

  stimuli <- unique(stimuli3$stim)

  x <- NULL
  x <- data.frame(matrix(unlist(combn(stimuli, 2, simplify=F)), nrow=276, byrow=T)) # 276 = (24*24-24)/2 #xxx how do i do this step, when i have a different number of observations for each participant? can i use this: "nrow = table(dfa$ID)" instead of 276?
  x$StimPairID <- seq(nrow(x))


  # Loop adding stimPair value to the current subset
  sub$StimPairID <- NA

  
  for (i in seq(nrow(x))){
    sub$StimPairID[
      (sub$left %in% x$X1[i] | sub$left %in% x$X2[i]) & 
      (sub$right %in% x$X1[i] | sub$right %in% x$X2[i])] = x$StimPairID[i]
  }

  
  # Add value so they all become unique across stim groups
  sub$StimPairID <- sub$StimPairID + (1000 * count)
  count <- count + 1

  
  # Combine with premade empty dataframe
  if (nrow(dfa_new) == 0) {
    dfa_new <- sub
    } else {
        dfa_new <- rbind(dfa_new, sub)
  }
}

```



remove trials of same generation forced choice (xxx Generation must mean period. So in my case, I don't want forced choice between for example two c1n1b1 condition type stimuli. That is a bit more unlikely in my case though, because I have waaay more combinations.)

```{r}
# Remove
dfa <- dfa_new %>% subset(ComplexityL != ComplexityR & NoiseL != NoiseR & BlankSpaceL != BlankSpaceR)
```


Create ‘Distance’ column based on generationL  (xxx so: Create ‘Distance’ column based on ComplexityL, one based on noiseL, and one based on BlankSpaceL, or should I make one single column for all three of them?)

```{r}

# relevel as factor
dfa$ComplexityL <- factor(dfa$ComplexityL, levels = c(1, 2, 3))
dfa$ComplexityR <- factor(dfa$ComplexityR, levels = c(1, 2, 3))

dfa$NoiseL <- factor(dfa$NoiseL, levels = c(1, 2, 3))
dfa$NoiseR <- factor(dfa$NoiseR, levels = c(1, 2, 3))

dfa$BlankSpaceL <- factor(dfa$BlankSpaceL, levels = c(1, 2, 3))
dfa$BlankSpaceR <- factor(dfa$BlankSpaceR, levels = c(1, 2, 3))



# when transformed from leveled factor; becomes 1, 2, and 3. (xxx don't know if this is true/necessary for me when my levels were already 1,2, and 3)
dfa$distanceC = as.numeric(dfa$ComplexityL)
dfa$distanceN = as.numeric(dfa$NoiseL)
dfa$distanceB = as.numeric(dfa$BlankSpaceL)



# subtract right from left
dfa$distanceC <- dfa$distanceC - as.numeric(dfa$ComplexityR)
dfa$distanceN <- dfa$distanceN - as.numeric(dfa$NoiseR)
dfa$distanceB <- dfa$distanceB - as.numeric(dfa$BlankSpaceR)



# Change variable before running models

dfa$StimPairID <- as.factor(dfa$StimPairID)

dfa$responseL <- as.factor(dfa$responseL)

dfa$ID <- as.factor(dfa$ID)

```



## Modelling

```{r the Null Model}
# define chains, iter, and controls (xxx is this the same for me?)
CHAINS = 2
CORES = 2
ITER = 1000


CONTROLS = list(
  max_treedepth = 20,
  adapt_delta=0.99)


# make subset
sub <- c(6, 7, 8, 9, 10) #xxx what is this?


# Bernoulli is the likelihood function  --> outcome is the log odds(?) xxx what?



### MODEL 0

# Construct models
a_c_m0 <- bf(responseL ~ 1) #  + (1 + distance | ID) + (1 | StimPairID)


# get priors to be set
get_prior(a_c_m0, dfa, family = bernoulli())


# set priors
a_c_prior0 <- c(
  prior(normal(0, 1.5), class = Intercept) #xxx find your own priors, once you get the df up and running
)


p <- rnorm(10000, 0, 1.5) # p = distribution. xxx Change numbers?

dens(p) # density plot (log odds)

dens(inv_logit(p)) # probabiloity for rate --> this is a nice prior (xxx check on my data)



# Run model based on priors alone
a_c_m0_prior <- brm(
   a_c_f0,
   data = subset(dfa, ID %in% sub),
   family = bernoulli(),
   prior = prior0,
   sample_prior = "only"
)


# prior predictive check
pp_check(a_c_m0_prior, nsamples=100)


## Better pp_check
y_pred <- posterior_linpred(a_c_m0_prior) # generate predictions from the model, but we don't want 0's and 1's , we want which rates are expected

# we want linear predictions before it is linked into log-odds. 
dens(inv_logit(y_pred)) # looks at the density now. Almost uniform distribution discounting extremes.



# Run model
a_c_m0 <- brm(
   a_c_f0,
   data = subset(dfa, ID %in% sub),
   family = bernoulli(),
   prior = prior0,
   sample_prior = TRUE
)



summary(a_c_m0)



# prior predictive check
pp_check(a_c_m0, nsamples=100)



## Better pp_check
y_pred1 <- posterior_linpred(a_c_m0)  
dens(inv_logit(y_pred1))
```



```{r Complexity models}
#xxx find better model names?

### Model 1:

#the model
a_c_f1 <- bf(responseL ~ 1 + distanceC + (1 + distanceC | ID) + (1 | StimPairID))


# get priors to be set
get_prior(a_c_f1, dfa, family = bernoulli())



a_c_prior1 <- c(       # xxx find your own priors
  prior(normal(0,1.5), class = Intercept),
  prior(normal(0,0.5), class = b),
  prior(normal(0,0.3), class = sd),
  prior(lkj(5), class = cor)
)



# Run prior model
a_c_m1_prior <- brm(
   a_c_f1,
   data = dfa, #subset(d2, ID %in% sub)
   family = bernoulli(),
   prior = a_c_prior1,
   sample_prior = "only"
)



# prior predictive check
pp_check(a_c_m1_prior, nsamples=100)



## Better pp_check
y_pred1 <- posterior_linpred(a_c_m1_prior)  
dens(inv_logit(y_pred1))



# Run model
a_c_m1 <- brm(
   a_c_f1,
   data = dfa,
   family = bernoulli(),
   prior = a_c_prior1,
   sample_prior = TRUE
)



# prior predictive check
pp_check(a_c_m1, nsamples=100)



## Better pp_check
y_pred1 <- posterior_linpred(a_c_m1)  
dens(inv_logit(y_pred1))



summary(a_c_m1)

hypothesis(a_c_m1,"distanceC > 0")  #what exactly does this mean?



exp(0.45) # chance xxx do i need to change these numbers?

inv_logit(0.45 + 0.28) # probability

inv_logit(0.45) 



# remember trace plots etc.
plot(a_c_m1)



# hypothesis testing

plot(hypothesis(a_c_m1,"distanceC > 0"))

hypothesis(a_c_m1,"distanceC > 0")





### Model 2

# formula
a_c_f2 <- bf(responseL ~ 1 + distanceC + I(distanceC)^2 + (1 + distanceC + I(distanceC)^2 | ID) + (1 | StimPairID))



# get priors to be set
get_prior(a_c_f2, dfa, family = bernoulli())  #xxx is family bernoulli?



a_c_prior2 <- c(     # xxx find your own priors
  prior(normal(0,1.5), class = Intercept),
  prior(normal(0,0.3), class = b),
  prior(normal(0,0.2), class = sd),
  prior(lkj(5), class = cor)
)



# Run prior model
a_c_m2_prior <- brm(
   a_c_f2,
   data = dfa,
   family = bernoulli(),
   prior = a_c_prior2,
   sample_prior = "only"
)



# prior predictive check
pp_check(a_c_m2_prior, nsamples=100)



## Better pp_check
y_pred1 <- posterior_linpred(a_c_m2_prior)  
dens(inv_logit(y_pred1))



# Run model
a_c_m2 <- brm(
   a_c_f2,
   data = dfa,
   family = bernoulli(),
   prior = a_c_prior2,
   sample_prior = TRUE
)



# prior predictive check
pp_check(a_c_m2, nsamples=100)



## Better pp_check
y_pred1 <- posterior_linpred(a_c_m2)  

dens(inv_logit(y_pred1))



summary(a_c_m2)

exp() # chance

inv_logit() # probability



plot(a_c_m2)

```





Model comparison

```{r}



###

a_c_m0 <- add_criterion(a_c_m0, criterion = c("bayes_R2", "loo"))

a_c_m1 <- add_criterion(a_c_m1, criterion = c("bayes_R2", "loo"))

a_c_m2 <- add_criterion(a_c_m2, criterion = c("bayes_R2", "loo"))





loo_compare(a_c_m1, a_c_m2) # number tries to estimate out of sample error. Baelines to 0. Best model is 0.

loo_model_weights(a_c_m1, a_c_m2)

```





## Controlling for problematic pictures xxx Not sure if I need this whole thing (chunk is untouched)

```{r}



# list of problematic stimuli (subjectively selected by Aske)

problemPics <- c("i3_c104_g8_id16", "i3_c104_g4_id12", "i3_c104_g1_id9",

                 "i4_c102_g4_id15", "i4_c102_g8_id315", "i4_c102_g1_",

                 "i4_c108_g4_id48", "i4_c108_g8_id52", "i4_c108_g1_id45",

                 "i3_c103_g8_id8", "i3_c103_g4_id4", "i3_c103_g1_id1")



# exclude problematic pictures in subset

d2sub <- d2 %>% subset(!left %in% problemPics) %>% subset(!right %in% problemPics)







### Model 3



# get priors to be set

get_prior(formula2.1, d2sub, family = bernoulli())



prior2.3 <- c(

  prior(normal(0,1.5), class = Intercept),

  prior(normal(0,0.5), class = b),

  prior(normal(0,0.3), class = sd),

  prior(lkj(5), class = cor)

)



# Run prior model

m2.3_prior <- brm(

   formula2.1,

   data = d2sub, #subset(d2, ID %in% sub)

   family = bernoulli(),

   prior = prior2.3,

   sample_prior = "only"

)



# prior predictive check

pp_check(m2.3_prior, nsamples=100)



## Better pp_check

y_pred1 <- posterior_linpred(m2.3_prior)  

dens(inv_logit(y_pred1))



# Run model

m2.3 <- brm(

   formula2.1,

   data = d2sub,

   family = bernoulli(),

   prior = prior2.3,

   sample_prior = TRUE

)



# prior predictive check

pp_check(m2.3, nsamples=100)



## Better pp_check

y_pred1 <- posterior_linpred(m2.3)  

dens(inv_logit(y_pred1))



summary(m2.3)

hypothesis(m2.3,"distance > 0")







exp(0.19) # chance

inv_logit(0.19) # probability







# remember trace plots etc.





# hypothesis testing

plot(hypothesis(m2.1,"distance > 0"))

hypothesis(m2.1,"distance > 0")







### Model 4



# get priors to be set

get_prior(formula2.2, d2sub, family = bernoulli())



prior2.4 <- c(

  prior(normal(0,1.5), class = Intercept),

  prior(normal(0,0.5), class = b),

  prior(normal(0,0.3), class = sd),

  prior(lkj(5), class = cor)

)



# Run prior model

m2.4_prior <- brm(

   formula2.2,

   data = d2sub, #subset(d2, ID %in% sub)

   family = bernoulli(),

   prior = prior2.4,

   sample_prior = "only"

)



# prior predictive check

pp_check(m2.4_prior, nsamples=100)



## Better pp_check

y_pred1 <- posterior_linpred(m2.4_prior)  

dens(inv_logit(y_pred1))



# Run model

m2.4 <- brm(

   formula2.2,

   data = d2sub,

   family = bernoulli(),

   prior = prior2.4,

   sample_prior = TRUE

)





m2.3 <- add_criterion(m2.3, criterion = c("bayes_R2", "loo"))

m2.4 <- add_criterion(m2.4, criterion = c("bayes_R2", "loo"))



exp2_compare1 <- loo_compare(m2.3, m2.4)

exp2_weights1 <- loo_model_weights(m2.3, m2.4)



exp2_compare1

exp2_weights1









```





## Controlling for Chain xxx What does that mean? (chunk is untouched)

Pre-process the data --> make new chain column

```{r}

# move df to old df

d2$chainL <- as.character(d2$chainL)

d2_old <- d2



# Create empty df

d2 <- d2[0,]



# Use chain group column to loop through them one by one and overwrite chains with a dummy.

for (i in 1:length(unique(d2_old$chainPair))){

  

  # subset data

  sub <- d2_old %>% subset(chainPair == i)

  

  sub$chainD <- sub$chainL

  

  # change chains to a dummy by chaingroup

  sub$chainD <- as.numeric(as.factor(sub$chainD))

  sub$chainD <- sub$chainD - 1

  

  # Combine with premade empty dataframe

  if (nrow(d2) == 0) {

    d2 <- sub

    } else {

        d2 <- rbind(d2, sub)}



}





# change chain to be a factor

d2$chainD <- as.factor(d2$chainD)



```



Chain control with all data (model 5-6) 

the simple model but two conditions - interaction or no interaction xxx (chunk is untouched)

```{r}



### Model 5



#the model

formula2.5 <- bf(responseL ~ 1 + distance + chainD + (1 + distance + chainD | ID) + (1 | StimPairID))



# get priors to be set

get_prior(formula2.5, d2, family = bernoulli())



prior2.5 <- c(

  prior(normal(0,1.5), class = Intercept),

  prior(normal(0,0.5), class = b),

  prior(normal(0,0.3), class = sd),

  prior(lkj(5), class = cor)

)



# Run prior model

m2.5_prior <- brm(

   formula2.5,

   data = d2, #subset(d2, ID %in% sub)

   family = bernoulli(),

   prior = prior2.5,

   sample_prior = "only"

)



# prior predictive check

pp_check(m2.5_prior, nsamples=100)



## Better pp_check

y_pred1 <- posterior_linpred(m2.5_prior)  

dens(inv_logit(y_pred1))



# Run model

m2.5 <- brm(

   formula2.5,

   data = d2,

   family = bernoulli(),

   prior = prior2.5,

   sample_prior = TRUE

)



# prior predictive check

pp_check(m2.5, nsamples=100)



## Better pp_check

y_pred1 <- posterior_linpred(m2.5)  

dens(inv_logit(y_pred1))







### Model 6



# formula

formula2.6 <- bf(responseL ~ 1 + distance*chainD  + (1 + distance*chainD | ID) + (1 | StimPairID))



# get priors to be set

get_prior(formula2.6, d2, family = bernoulli())



prior2.6 <- c(

  prior(normal(0,1.5), class = Intercept),

  prior(normal(0,0.3), class = b),

  prior(normal(0,0.2), class = sd),

  prior(lkj(5), class = cor)

)



# Run prior model

m2.6_prior <- brm(

   formula2.6,

   data = d2,

   family = bernoulli(),

   prior = prior2.6,

   sample_prior = "only"

)



# prior predictive check

pp_check(m2.6_prior, nsamples=100)



## Better pp_check

y_pred1 <- posterior_linpred(m2.6_prior)  

dens(inv_logit(y_pred1))



# Run model

m2.6 <- brm(

   formula2.6,

   data = d2,

   family = bernoulli(),

   prior = prior2.6,

   sample_prior = TRUE

)



# prior predictive check

pp_check(m2.6, nsamples=100)



## Better pp_check

y_pred1 <- posterior_linpred(m2.6)  

dens(inv_logit(y_pred1))





```



Results

```{r}

summary(m2.5)

summary(m2.3)

#hypothesis(m2.5,"distance > 0")





exp(0.45) # chance

inv_logit(0.45 + 0.28) # probability







# remember trace plots etc.

plot(m2.5)





# hypothesis testing

#plot(hypothesis(m2.5,"distance > 0"))

#hypothesis(m2.5,"distance > 0")







summary(m2.6)

#exp() # chance

#inv_logit() # probability



plot(m2.6)





```





Chain control without prob pics (model 7-8) - that is the best one

```{r}





# Overwrite the original subset, so it will include chainD as well.

d2sub <- d2 %>% subset(!left %in% problemPics) %>% subset(!right %in% problemPics)



### Model 7



#the model

formula2.7 <- bf(responseL ~ 1 + distance + chainD + (1 + distance + chainD | ID) + (1 | StimPairID))



# get priors to be set

get_prior(formula2.7, d2sub, family = bernoulli())



prior2.7 <- c(

  prior(normal(0,1.5), class = Intercept),

  prior(normal(0,0.5), class = b),

  prior(normal(0,0.3), class = sd),

  prior(lkj(5), class = cor)

)



# Run prior model

m2.7_prior <- brm(

   formula2.7,

   data = d2sub, #subset(d2, ID %in% sub)

   family = bernoulli(),

   prior = prior2.7,

   sample_prior = "only"

)



# prior predictive check

pp_check(m2.7_prior, nsamples=100)



## Better pp_check

y_pred1 <- posterior_linpred(m2.7_prior)  

dens(inv_logit(y_pred1))



# Run model

m2.7 <- brm(

   formula2.7,

   data = d2sub,

   family = bernoulli(),

   prior = prior2.7,

   sample_prior = TRUE

)



# prior predictive check

pp_check(m2.7, nsamples=100)



## Better pp_check

y_pred1 <- posterior_linpred(m2.7)  

dens(inv_logit(y_pred1))









### Model 8



#the model

formula2.8 <- bf(responseL ~ 1 + distance * chainD + (1 + distance * chainD | ID) + (1 | StimPairID))



# get priors to be set

get_prior(formula2.8, d2sub, family = bernoulli())



prior2.8 <- c(

  prior(normal(0,1.5), class = Intercept),

  prior(normal(0,0.5), class = b),

  prior(normal(0,0.3), class = sd),

  prior(lkj(5), class = cor)

)



# Run prior model

m2.8_prior <- brm(

   formula2.8,

   data = d2sub, #subset(d2, ID %in% sub)

   family = bernoulli(),

   prior = prior2.8,

   sample_prior = "only"

)



# prior predictive check

pp_check(m2.8_prior, nsamples=100)



## Better pp_check

y_pred1 <- posterior_linpred(m2.8_prior)  

dens(inv_logit(y_pred1))



# Run model

m2.8 <- brm(

   formula2.8,

   data = d2sub,

   family = bernoulli(),

   prior = prior2.8,

   sample_prior = TRUE

)



# prior predictive check

pp_check(m2.8, nsamples=100)



## Better pp_check

y_pred1 <- posterior_linpred(m2.8)  

dens(inv_logit(y_pred1))



```



Results

```{r}



summary(m2.7)

summary(m2.8)

plot(hypothesis(m2.8,"distance > 0"))

plot(m2.8)







exp(0.19) # chance

inv_logit(0.19) # probability







# remember trace plots etc.





# hypothesis testing

#plot(hypothesis(m2.1,"distance > 0"))

#hypothesis(m2.1,"distance > 0")









```



## Model comparisons

```{r}

# model contrlling for pics

m2.3 <- add_criterion(m2.3, criterion = c("bayes_R2", "loo"))



# models controlling for chain on all data

m2.5 <- add_criterion(m2.5, criterion = c("bayes_R2", "loo"))

m2.6 <- add_criterion(m2.6, criterion = c("bayes_R2", "loo"))



# models controlling for chain on all data

m2.7 <- add_criterion(m2.7, criterion = c("bayes_R2", "loo"))

m2.8 <- add_criterion(m2.8, criterion = c("bayes_R2", "loo"))







# first models

exp2_compare1 <- loo_compare(m2.1, m2.2) 

exp2_weights1 <- loo_model_weights(m2.1,m2.2)

exp2_compare1

exp2_weights1 # most simple model is better





# control models for chain with all data

exp2_compare2 <- loo_compare(m2.5, m2.6) 

exp2_weights2 <- loo_model_weights(m2.5,m2.6)

exp2_compare2

exp2_weights2 # interaction control model is better





# compare all models on all data

exp2_compare3 <- loo_compare(m2.1, m2.2, m2.5, m2.6) 

exp2_weights3 <- loo_model_weights(m2.1, m2.2, m2.5, m2.6)

exp2_compare3

exp2_weights3 # Control model with interaction effect was found most credible



# compare best first model with the two control chain models

exp2_compare4 <- loo_compare(m2.1, m2.5, m2.6) 

exp2_weights4 <- loo_model_weights(m2.1, m2.5, m2.6)

exp2_compare4

exp2_weights4 #comparison without quadratic model --> again 2.6 is by far the best model



# control models for chain without prob pics

exp2_compare5 <- loo_compare(m2.7, m2.8) 

exp2_weights5 <- loo_model_weights(m2.7,m2.8)

exp2_compare5

exp2_weights5



# compare with the first not controlling for chain

exp2_compare6 <- loo_compare(m2.3, m2.7, m2.8) 

exp2_weights6 <- loo_model_weights(m2.3, m2.7, m2.8)

exp2_compare6 

exp2_weights6





summary(m2.1)

summary(m2.2)

summary(m2.3)

summary(m2.4)

summary(m2.5)

summary(m2.6)

summary(m2.7)

summary(m2.8)





```





# Reporting the best model

```{r}



# both controlling for problematic pictures and chain group

summary(m2.8)

hypothesis(m2.8, "distance:chainD1 > 0")



# Relative effect scale, ignore baserate

exp(0.51) #  the odds of selecting the left stimulus increase 67% when the predictor ‘distance’ increases one unit



#absolute effect, take base rate into account (xxx what is the base rate?)

inv_logit(0.37)

inv_logit(0.37 + 0.51)

inv_logit(0.37 + 0.51) - inv_logit(0.37) # A positive unit change in the predictor elicits a 11.5% increase in probability of choosing the left stimulus





# great effect

hypothesis(m2.8,"distance > 0")



# no effects

hypothesis(m2.8,"chainD1 > 0")

hypothesis(m2.8,"distance:chainD1 > 0")



# plot results

plot(hypothesis(m2.8,"distance > 0")) # the priors do not seem too sceptical as the data does not try to escape it...



plot(m2.8)



conditional_effects(m2.8)



```





## Plots

```{r}



# Change response L back to numeric

d2$responseL <- as.numeric(as.character(d2$responseL))



# Create summary dataset for visualisation

plotSum <- d2 %>% group_by(ID, distance) %>% summarise(

  LeftChoice = mean(responseL)

)





library(pacman)

p_load(extrafont)

font_import(pattern="[T/t]imes")

loadfonts(device="win")



Exp2_MainPlot <- ggplot(plotSum, aes(distance, LeftChoice)) + 

  geom_line(aes(group=ID,color=ID),alpha=0.6) +

  geom_point(aes(group=ID,color=ID),alpha=0.6)+

  geom_smooth(method=lm, color = "red") +

  scale_color_discrete(guide=FALSE) +

  scale_x_continuous(breaks = c(-2, -1, 0, 1, 2),labels=c("-2","-1", "", "1", "2")) +

  

  # THEMES

  theme_grey() +

  theme(

    text = element_text(family = "Times New Roman"),

    legend.position="top",

    plot.subtitle=element_text(face="italic",size=14,colour="grey40"),

    plot.title=element_text(size=21,face="bold")) +

  labs(title="\nExperiment 2",

       subtitle="Intentionality",

       x=expression("Generation distance from right to left"),

       y=expression("Rate of choosing the left stimulus")) +

  NULL

  

Exp2_MainPlot 

```



